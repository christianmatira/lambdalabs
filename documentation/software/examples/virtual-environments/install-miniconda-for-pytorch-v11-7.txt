
Check your:
   pip -v list | grep -v "/usr/lib/python3/dist-packages"
    * This will show you any package installed that is not part of Lambda Stack or Ubuntu
      (Ideally these other packages should only be in a virtual environment Python venv or Anaconda/Miniconda)
    * The Common fix is to:
       Move the ~/.local out of the way.  This is where 'pip' installs if you are not in a virtual env
          $ mv ~/.local ~/.local.bak
       Move the /usr/local, this is where local site software is suppose to be installed, but NVIDIA sometimes
       installs their software there, and pip installs packages there if you run 'sudo pip install' 
          $ sudo mv /usr/local /usr/local.bak
       Or you can remove each package from: 'pip -v list | grep "/usr/local"'
          $ sudo pip uninstall package_name

1. Install Miniconda:
   From: https://docs.conda.io/en/latest/miniconda.html#linux-installers
   Current version for Python 3.10:
    $ wget https://repo.anaconda.com/miniconda/Miniconda3-py310_22.11.1-1-Linux-x86_64.sh
    $ bash Miniconda3-py310_22.11.1-1-Linux-x86_64.sh
 
2. Activate the environment for miniconda to be active:
   $ . $HOME/.bashrc

   If you want Miniconda installed but not always active, I would not mix Miniconda with python venv,
   since Miniconda blocks the default install.

   I do the following so conda is not always activated, and I can switch between Miniconda and Python venv:
    (base) $ conda deactivate
    $ conda config --set auto_activate_base false

3. Create a environment:
     a. Create from the command line:
        $ conda create -n torch_cuda_11-7 pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
     b. Activate the environement:
        $  conda activate torch_cuda_11-7

4. Run the code:
$ python -c 'import torch ; print("Is available: ", torch.cuda.is_available()) ; print("Pytorch CUDA Compiled version: ", torch._C._cuda_getCompiledVersion()) ; print("Pytorch version: ", torch.__version__) ; print("pytorch file: ", torch.__file__) ; available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())] ; print("Available GPUS: ",len(available_gpus))'

Is available:  True
Pytorch CUDA Compiled version:  11070
Pytorch version:  2.0.1
pytorch file:  /home/support/miniconda3/envs/torch_cuda_11-7/lib/python3.11/site-packages/torch/__init__.py
Available GPUS:  4


